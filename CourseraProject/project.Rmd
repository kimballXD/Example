---
title: "Course Project of Pratical Machine Learning"
author: "Chun-Sheng Wu"
output: html_document
---


# Introduction

  The objective of this study was to classify subjects' behavior using the data generated by wearable meters. The dataset used in this study can be accessed from  [here](http://groupware.les.inf.puc-rio.br/har). The data in the dataset were generated from a experiment. Subjects weared meters which could record their body movement, and performed 5 types of behavior during the experiment. The behavoir subject had done and the correspoding data generated by wearable meters were collected in the dataset. 5 behavioral types were indicated by "classe" column in the dataset, with value A~E respectively. Using the dataset metioned above, I tried to build a classifier which could recognize subject's behavior during they are performing behavior.

```{r, echo=F,message=F, warning='F',results='hide'}

library(caret)
if (!('./data' %in% list.dirs())) 
  dir.create(c('data'))
if (!('training.csv' %in% list.files('data')))
  download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv',destfile ='data/training.csv' ,mode ='wb')

if (!('testing.csv' %in% list.files('data')))
download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv',destfile ='data/testing.csv' ,mode ='wb')
```


# Data Preparation
 
  In this study, the first step of preparing data was to pick out the data which had the same "form" as the testing data. There were two types of data entries in the training dataset. One type had "yes" value in 'new window' column, and the other type had the value "no". The difference betwee "yes" and "no" type data entry was: "No-type" entry had many columns whose values were all NA. However, "yes-type" entry usually had normal values in those columns. Since the data entries in the testing dataset were all "no-type", I first pick up the "no-type" data in the training dataset. Then, I removed all the columns that contained only NA value.
  
  Second, I removed those columns whose value had no logical relation with the "classe" variable we wanted to predict. These columns were all indication columns, which were: raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, num_window, new_window, user_name , and X(entry's id). 
  
  The whole process described above could be done in the following chunks. In result, there were 19216 entries, 52 varaibles left for the modeling process. All variables contained 0 missing value.
  
```{r, warning='F'}
clean<-function(data){
  colNames<-names(data)
  dropCol<-c('raw_timestamp_part_1','raw_timestamp_part_2','cvtd_timestamp','num_window','new_window','user_name','classe','X')
  preCol<-colNames[!colNames %in% dropCol]
  data2<-as.data.frame(apply(data[,preCol],2,as.numeric))
  dropCol2<-names(data2)[sapply(data2, function(x) sum(is.na(x))==dim(data2)[1])]
  preCol2<-names(data2)[!names(data2) %in% dropCol2]
  data2<-data2[,preCol2]
  return(data2)
}

data<-read.csv('data/training.csv',na.strings =c('NA',"",'#DIV/0!'))
data<-data[data$new_window=='no',]
classe<-data$classe
data2<-clean(data)
```

  
# Modeling
  
  I applied conditional inference tree(hereafter "ctree") model to predict the "classe" variable in the dataset, with 10-fold cross validation. It could be simply implemented by the following commands using 3rd party "caret" library. It took about 7 minutes to train the model with my laptop, which had an Intel i5-6200U CPU. 
  
```{r,message=F, warning='F',cache=T}
trControl<-trainControl(method='cv',number=10)
set.seed<-5566
ctree<-train(classe~.,method='ctree',data=data2, trControl=trControl)
```


# Result
  
  The performance of the ctree modle on the training dataset could be assessed with the confusionMatirx command:

```{r,message=F, warning='F'}
result<-confusionMatrix(classe,predict(ctree,data2))
overall<-as.data.frame(round(result$overall,digits=4))
names(overall)=c('value')
result$table
overall
```


  The accuracy of the ctree model was about 94% in this study, which might be considered as acceptible. However, it was a optimistic predication of accuracy, since it did not take out-of-sample error into assessment. A more practicle assessment of accuracy could be obtained from the model object itself.
  
  
  
```{r}
ctree$result
```

  As showed, a practicle assessment of accuracy was about 89%. 


# Prediction

  The prediction of behavior in the test dataset could be obtained with the following codes.
  
```{r}
testData<-read.csv('data/testing.csv',na.strings =c('NA',"",'#DIV/0!'))
testData2<-clean(testData)
pred<-predict(ctree,testData2)
pred
```

